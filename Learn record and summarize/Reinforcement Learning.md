# 强化学习基础

强化学习（reinforcement learning，RL）讨论的问题是智能体（agent）怎么在复杂、不确定的环境（environment）中最大化它能获得的奖励。强化学习由两部分组成：智能体和环境。在强化学习过程中，智能体与环境一直在交互。智能体在环境中获取某个状态后，它会利用该状态输出一个动作 （action），这个动作也称为决策（decision）。然后这个动作会在环境中被执行，环境会根据智能体采取的动作，输出下一个状态以及当前这个动作带来的奖励。智能体的目的就是尽可能多地从环境中获取奖励。

<img src="https://datawhalechina.github.io/easy-rl/img/ch1/1.1.png" style="zoom: 50%;" />

在监督学习过程中，有两个假设：

- 输入的数据（标注的数据）都应是没有关联的。因为如果输入的数据有关联，学习器（learner）是不好学习的。
- 需要告诉学习器正确的标签是什么，这样它可以通过正确的标签来修正自己的预测。

在强化学习中，监督学习的两个假设其实都不能得到满足。强化学习之所以困难，是因为智能体不能得到即时的反馈，然而我们依然希望智能体在这个环境中学习。

