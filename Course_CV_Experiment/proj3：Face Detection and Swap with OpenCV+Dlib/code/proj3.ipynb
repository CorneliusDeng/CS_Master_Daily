{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![intro](./intro.png)\n",
    "\n",
    "# Project III. Face Detection and Swap with OpenCV+Dlib\n",
    "1. Extract faces from a given image (68 landmarks detection)\n",
    "2. Mesh the faces from two different images\n",
    "3. Swap the faces of 2 persons\n",
    "\n",
    "**The code implementation of Face Swap is written by students, while all visualization codes are provided.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Please install required packages and make sure the version are valid \n",
    "\n",
    "Installation of dlib library is bit tricky you have to follow some steps:\n",
    "1. Install **visual studio (2017 or 2022)** - refer to this [link](https://visualstudio.microsoft.com/zh-hans/downloads/)\n",
    "2. In visual studio one need to install CMake package\n",
    "3. After installation from Visual studio we have to install it again using - `pip install cmake`\n",
    "4. Here comes the last part now, we have to install dlib by - `pip install dlib`\n",
    "\n",
    "### We will start by importing some required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdlib\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we will load two images of different persons, resizing them to (300, 300)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = Image.open('../data/person1.jpg')\n",
    "image1 = image1.resize((300,300))\n",
    "image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = Image.open('../data/person2.jpg')\n",
    "image2 = image2.resize((300,300))\n",
    "image2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will convert our images into numpy array and use cv2 to convert it into grayscale. We will also create empty image or mask similar to our source image with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting image to array and converting them to grayscale\n",
    "img1 = np.array(image1)\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2 = np.array(image2)\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Face detector and Face landmarks predictor using dlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initalizing frontal face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"../data/pretrained_weights/shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code implemented by students in `student.py`:\n",
    "1. the `get_landmarks()` first use `detector` to localize face bbox and then use `predictor` to detect landmarks (68 points, dtype: np.array).\n",
    "2. the `get_face_mask()` gets the face mask according to landmarks.\n",
    "3. the `get_delaunay_triangulation()` gets the face mesh triangulation according to landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from student import get_landmarks, get_face_mask, get_delaunay_triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face 1\n",
    "landmarks1 = get_landmarks(detector, predictor, img1_gray)\n",
    "\n",
    "# Mask\n",
    "convexhull1, mask1 = get_face_mask(img1_gray, landmarks1)\n",
    "face1 = cv2.bitwise_and(img1, img1, mask=mask1)\n",
    "\n",
    "# Delaunay triangulation\n",
    "triangles1 = get_delaunay_triangulation(landmarks1, convexhull1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face 2\n",
    "landmarks2 = get_landmarks(detector, predictor, img2_gray)\n",
    "\n",
    "# Mask\n",
    "convexhull2, mask2 = get_face_mask(img2_gray, landmarks2)\n",
    "\n",
    "# Delaunay triangulation\n",
    "triangles2 = get_delaunay_triangulation(landmarks2, convexhull2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection and Landmark Detection Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visulize_face_landmarks(img, mask, landmarks, triangles):\n",
    "    plt.figure(figsize=(100, 300))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    face = cv2.bitwise_and(img, img, mask=mask)\n",
    "    plt.imshow(face)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    img_landmark = img.copy()\n",
    "    \n",
    "    for triangle in triangles:\n",
    "        cv2.polylines(img_landmark, [np.array(triangle, np.int32).reshape((-1, 1 ,2))], True, (255, 255, 255), 1)\n",
    "    for i, (x, y) in enumerate(landmarks):\n",
    "        cv2.circle(img_landmark, (x, y), 3, (0, 255, 0), -1)\n",
    "\n",
    "    \n",
    "    plt.imshow(img_landmark)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visulize_face_landmarks(img1, mask1, landmarks1, triangles1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visulize_face_landmarks(img2, mask2, landmarks2, triangles2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let us swap the source face (person1 in example) to target image (person2 in example).\n",
    "Code implemented by students in `student.py`:\n",
    "1. `transformation_from_points()` calculate the affine transformation matrix M to warp the face of person2 to match person1.\n",
    "2. `warp_img()` utilize the affine transformation matrix M to transform the img."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from student import transformation_from_landmarks, warp_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### swap the face of person1 to match person2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "img2: target img (person2)\n",
    "warped_img1: warped face img of person1\n",
    "face_mask1: warped face mask of person1\n",
    "'''\n",
    "#TODO: Implement this function!\n",
    "warped_mask1 = None\n",
    "warped_img1 = None\n",
    "output_img = img2 * (~warped_mask1) + warped_img1 * warped_mask1\n",
    "plt.imshow(output_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) On Opencv we have a built-in function called “seamlessClone” that does this operation automatically. We need to take the swapped face, take the original destination image and it’s mask to cut out the face, we need to get the center of the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Implement this function!\n",
    "seamlessclone = cv2.seamlessClone( ... ) # Your Code here\n",
    "plt.imshow(seamlessclone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
